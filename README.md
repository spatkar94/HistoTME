HistoTME
==============
![](HistoTME_regression/HistoTME_outline.png)


## Overview 
The code in the folder HistoTME_regression can be used to run attention-based multiple instance learning (AB-MIL) to predict TME molecular signatures from histopathology slides. In order to run experiments on the histopathology datasets, please download the features extracted by the UNI foundation model for the TCGA and CPTAC H&E whole slide images (WSI).

The code in the folder HistoTME_downstream can be used to run downstream unsupervised clustering analyses and prediction of immune checkpoint inhibitor response in NSCLC patients. Prior to running these experiments, features must be extracted from the WSIs.

Manuscript preprint available [here](https://www.medrxiv.org/content/10.1101/2024.06.11.24308696v1).

## Installation and prerequisites
Tested with Python 3.9. Install requirements using:
```
pip install -r requirements.txt
```
## How to use
### Data Preparation
#### TCGA and CPTAC data
The TCGA and CPTAC whole slide imaging data can be found online from [GDC](https://portal.gdc.cancer.gov/), [TCIA](https://wiki.cancerimagingarchive.net/display/Public/CPTAC+Imaging+Proteomics) data portals. The downloaded whole slide images should be stored in a single directory as shown below:
```bash
├── WSI_Directory
│   ├── slide_1.svs
│   ├── slide_2.svs
│   ├── ...
...
...
│   ├── slide_N.svs

```
After downloading the WSI run the following WSI preprocessing script to tesselate each whole slide image into a collection of non-overlapping 512x512 pixel tiles scanned at 20x magnification and extract features using [UNI](https://huggingface.co/MahmoodLab/UNI), a pre-trained foundation model:
```
cd data_preprocessing/
./run_UNI.sh
```
The extracted features will be saved in a h5py file with each entry corresponding to a tile along with its physical coordinates and the foundation model-generated feature embeddings.
```
dict{'coords': (x,y), 'features': <embeddings>}
```

To calculate expression of TME signatures from bulk transcriptomics data please see the [following github repository](https://github.com/BostonGene/MFP/blob/master/TME_Classification.ipynb). 

#### Format Preparation
The extracted features should be in h5py file format to be read. A csv containing both TCGA and CPTAC cohorts should then be made with the transcriptomic-derived TME signatures and a file path to the extracted features. See [HistoTME_regression/sample_data.csv](HistoTME_regression/sample_data.csv) for an example. 

### Training
Training can be run for multi-task or single-task AB-MIL using:
```
cd HistoTME_regression/
./run_multitask.sh
./run_single_tasks.sh
```

### Prediction
Predictions using multitask or singletask AB-MIL can be run on the CPTAC or TCGA cohort using:
```
cd HistoTME_regression/
python predict_CPTAC_TCGA.py --task=multitask --cohort=CPTAC
python predict_CPTAC_TCGA.py --task=singletask --cohort=CPTAC
python predict_CPTAC_TCGA.py --task=multitask --cohort=TCGA
python predict_CPTAC_TCGA.py --task=singletask --cohort=TCGA
```

### Attention Interpretability
Heatmaps for the multi-task AB-MIL + UNI model can be generated by using:
```
cd HistoTME_regression/
python get_heatmaps.py
```
These can then be visualized using:
```
cd HistoTME_regression/
python generate_attn_maps.py \
--svs_loc </path/to/svs/files> \
--attn_maps_loc </path/to/raw/attention/values> \
--patch_size <selected patch size, default = 512> \
--mag <selected magnification, default = 20> \
--out_dir </path/to/output/directory>

```
## Model weights
For inquiries about HistoTME model weights please contact the corresponding authors directly.  The codes are intended to be used for research purposes only. Please see the [license](LICENSE)

## Questions and Issues
If you find any bugs or have any questions about this code please contact: [Sushant Patkar](patkar.sushant@nih.gov) or [Alex Chen](alche@sas.upenn.edu)

## Citation
If you found our work useful in your research please consider citing this work as follows: 
```
@article {Patkar2024.06.11.24308696,
	author = {Patkar, Sushant and Chen, Alex and Basnet, Alina and Bixby, Amber and Rajendran, Rahul and Chernet, Rachel and Faso, Susan and Kumar, Prashant A. and Desai, Devashish and El-Zammar, Ola and Curtiss, Christopher and Carello, Saverio J. and Nasr, Michel and Choyke, Peter and Harmon, Stephanie and Turkbey, Baris and Jamaspishvili, Tamara},
	title = {Predicting the Tumor Microenvironment Composition and Immunotherapy Response in Non-Small Cell Lung Cancer from Digital Histopathology Images},
	elocation-id = {2024.06.11.24308696},
	year = {2024},
	doi = {10.1101/2024.06.11.24308696},
	publisher = {Cold Spring Harbor Laboratory Press},
  URL = {https://www.medrxiv.org/content/early/2024/06/12/2024.06.11.24308696},
	eprint = {https://www.medrxiv.org/content/early/2024/06/12/2024.06.11.24308696.full.pdf},
	journal = {medRxiv}
}
```

## Acknowledgments
This project was supported by an award from Upstate Foundation's Hendricks Endowment. Data (digital images and clinical meta-data) from the institutional cohort was generated at the Pathology Research Core Lab using institutional resources and support. 

